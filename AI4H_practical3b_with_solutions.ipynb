{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit_learning_model_training_unpacked.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rG219z6ohceY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iru8mbpme2Ch"
      },
      "source": [
        "# Sklearn model building example\n",
        "\n",
        "Sklearn comes with many more functionalities than just training the parameters of a model. The main benefit of sklearn is actually in organizing the workflow *around* training a model. Think of functionalities such as splitting the data or cross-validation, but also preprocessing of data and the use of pipelines. \n",
        "\n",
        "Training the parameters of a machine learning model is not difficult. But ensuring that the process is done in such a way that your results give you the best possible representation of how well your model will perform for the next instance in your process can go wrong in many, many different ways.\n",
        "\n",
        "In this notebook we go through a pipeline example, where some fundamental functionalities of sklearn are unpacked, small-step by small-step, such that you will understand far better what is happening under the hood when training models using sklearn.\n",
        "\n",
        "Needless to say, there is much, much more to sklearn than shown below. Please do visit https://scikit-learn.org/stable/ to further investigate all the possibilities of this important package."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As always, we start with importing the relevant modules."
      ],
      "metadata": {
        "id": "C0J35f56OUDl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qB--SMu81rW"
      },
      "source": [
        "#import relevant modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMQVPxDXjEzo"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We work with a toy dataset, containing sonar data which can be used to classify objects as being either a Mine or a Rock. More information on the dataset can be found at: https://datahub.io/machine-learning/sonar."
      ],
      "metadata": {
        "id": "70vpmsAFO8Nj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "EtEXZweE9NPD",
        "outputId": "bfa56861-dd12-4aa8-bf14-cb2ac4367bfd"
      },
      "source": [
        "df = pd.read_csv('https://datahub.io/machine-learning/sonar/r/sonar.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-459c99f0-4e61-439f-8937-4bbec1439f3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>...</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-459c99f0-4e61-439f-8937-4bbec1439f3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-459c99f0-4e61-439f-8937-4bbec1439f3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-459c99f0-4e61-439f-8937-4bbec1439f3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
              "0       0.0200       0.0371       0.0428       0.0207       0.0954   \n",
              "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
              "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
              "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
              "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
              "\n",
              "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
              "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
              "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
              "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
              "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
              "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
              "\n",
              "   attribute_52  attribute_53  attribute_54  attribute_55  attribute_56  \\\n",
              "0        0.0027        0.0065        0.0159        0.0072        0.0167   \n",
              "1        0.0084        0.0089        0.0048        0.0094        0.0191   \n",
              "2        0.0232        0.0166        0.0095        0.0180        0.0244   \n",
              "3        0.0121        0.0036        0.0150        0.0085        0.0073   \n",
              "4        0.0031        0.0054        0.0105        0.0110        0.0015   \n",
              "\n",
              "   attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
              "0        0.0180        0.0084        0.0090        0.0032   Rock  \n",
              "1        0.0140        0.0049        0.0052        0.0044   Rock  \n",
              "2        0.0316        0.0164        0.0095        0.0078   Rock  \n",
              "3        0.0050        0.0044        0.0040        0.0117   Rock  \n",
              "4        0.0072        0.0048        0.0107        0.0094   Rock  \n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-NnpFZ7Eu9p",
        "outputId": "5e30df67-77e2-4c99-8ac4-c33fd5bc9af9"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 61 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   attribute_1   208 non-null    float64\n",
            " 1   attribute_2   208 non-null    float64\n",
            " 2   attribute_3   208 non-null    float64\n",
            " 3   attribute_4   208 non-null    float64\n",
            " 4   attribute_5   208 non-null    float64\n",
            " 5   attribute_6   208 non-null    float64\n",
            " 6   attribute_7   208 non-null    float64\n",
            " 7   attribute_8   208 non-null    float64\n",
            " 8   attribute_9   208 non-null    float64\n",
            " 9   attribute_10  208 non-null    float64\n",
            " 10  attribute_11  208 non-null    float64\n",
            " 11  attribute_12  208 non-null    float64\n",
            " 12  attribute_13  208 non-null    float64\n",
            " 13  attribute_14  208 non-null    float64\n",
            " 14  attribute_15  208 non-null    float64\n",
            " 15  attribute_16  208 non-null    float64\n",
            " 16  attribute_17  208 non-null    float64\n",
            " 17  attribute_18  208 non-null    float64\n",
            " 18  attribute_19  208 non-null    float64\n",
            " 19  attribute_20  208 non-null    float64\n",
            " 20  attribute_21  208 non-null    float64\n",
            " 21  attribute_22  208 non-null    float64\n",
            " 22  attribute_23  208 non-null    float64\n",
            " 23  attribute_24  208 non-null    float64\n",
            " 24  attribute_25  208 non-null    float64\n",
            " 25  attribute_26  208 non-null    float64\n",
            " 26  attribute_27  208 non-null    float64\n",
            " 27  attribute_28  208 non-null    float64\n",
            " 28  attribute_29  208 non-null    float64\n",
            " 29  attribute_30  208 non-null    float64\n",
            " 30  attribute_31  208 non-null    float64\n",
            " 31  attribute_32  208 non-null    float64\n",
            " 32  attribute_33  208 non-null    float64\n",
            " 33  attribute_34  208 non-null    float64\n",
            " 34  attribute_35  208 non-null    float64\n",
            " 35  attribute_36  208 non-null    float64\n",
            " 36  attribute_37  208 non-null    float64\n",
            " 37  attribute_38  208 non-null    float64\n",
            " 38  attribute_39  208 non-null    float64\n",
            " 39  attribute_40  208 non-null    float64\n",
            " 40  attribute_41  208 non-null    float64\n",
            " 41  attribute_42  208 non-null    float64\n",
            " 42  attribute_43  208 non-null    float64\n",
            " 43  attribute_44  208 non-null    float64\n",
            " 44  attribute_45  208 non-null    float64\n",
            " 45  attribute_46  208 non-null    float64\n",
            " 46  attribute_47  208 non-null    float64\n",
            " 47  attribute_48  208 non-null    float64\n",
            " 48  attribute_49  208 non-null    float64\n",
            " 49  attribute_50  208 non-null    float64\n",
            " 50  attribute_51  208 non-null    float64\n",
            " 51  attribute_52  208 non-null    float64\n",
            " 52  attribute_53  208 non-null    float64\n",
            " 53  attribute_54  208 non-null    float64\n",
            " 54  attribute_55  208 non-null    float64\n",
            " 55  attribute_56  208 non-null    float64\n",
            " 56  attribute_57  208 non-null    float64\n",
            " 57  attribute_58  208 non-null    float64\n",
            " 58  attribute_59  208 non-null    float64\n",
            " 59  attribute_60  208 non-null    float64\n",
            " 60  Class         208 non-null    object \n",
            "dtypes: float64(60), object(1)\n",
            "memory usage: 99.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGa7Cpl0Dj1N"
      },
      "source": [
        "As we have no categorical features in our data (only the outcome variable Class is categorical), we add two categorical features to our data, such that we can demonstrate the functionalities relating to this data type."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1\n",
        "- add a 'batch' feature to the dataframe, containing the levels 'first' (60 rows), 'second' (60 rows), 'third' (remaining rows).\n",
        "- add a 'location' feature to the dataframe, containing the levels 'loc_A' (20 rows), 'loc_B' (30 rows), 'loc_C' (40 rows), 'loc_D' (50 rows), 'loc_E' (remaining rows)."
      ],
      "metadata": {
        "id": "JQRrVCwKPoLC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "_5ddr3E6EoSd",
        "outputId": "3dcdc36a-24b5-4cf3-fb82-d108b1f0f0ec"
      },
      "source": [
        "# answer Q1\n",
        "df['batch'] = ['first']*60+['second']*60 + ['third']* (len(df)-60-60)\n",
        "df['location'] = ['loc_A']*20+['loc_B']*30 +['loc_C']*40 +['loc_D']*50 + ['loc_E']* (len(df)-20-30-40-50)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-362bb894-1994-44a8-a75b-c374c7c47b71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>...</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>Class</th>\n",
              "      <th>batch</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 63 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-362bb894-1994-44a8-a75b-c374c7c47b71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-362bb894-1994-44a8-a75b-c374c7c47b71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-362bb894-1994-44a8-a75b-c374c7c47b71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
              "0       0.0200       0.0371       0.0428       0.0207       0.0954   \n",
              "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
              "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
              "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
              "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
              "\n",
              "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
              "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
              "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
              "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
              "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
              "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
              "\n",
              "   attribute_54  attribute_55  attribute_56  attribute_57  attribute_58  \\\n",
              "0        0.0159        0.0072        0.0167        0.0180        0.0084   \n",
              "1        0.0048        0.0094        0.0191        0.0140        0.0049   \n",
              "2        0.0095        0.0180        0.0244        0.0316        0.0164   \n",
              "3        0.0150        0.0085        0.0073        0.0050        0.0044   \n",
              "4        0.0105        0.0110        0.0015        0.0072        0.0048   \n",
              "\n",
              "   attribute_59  attribute_60  Class  batch  location  \n",
              "0        0.0090        0.0032   Rock  first     loc_A  \n",
              "1        0.0052        0.0044   Rock  first     loc_A  \n",
              "2        0.0095        0.0078   Rock  first     loc_A  \n",
              "3        0.0040        0.0117   Rock  first     loc_A  \n",
              "4        0.0107        0.0094   Rock  first     loc_A  \n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekZuHB10GLRL",
        "outputId": "0f3a8ceb-8fd3-4995-9554-8e74c6fbf085"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 63 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   attribute_1   208 non-null    float64\n",
            " 1   attribute_2   208 non-null    float64\n",
            " 2   attribute_3   208 non-null    float64\n",
            " 3   attribute_4   208 non-null    float64\n",
            " 4   attribute_5   208 non-null    float64\n",
            " 5   attribute_6   208 non-null    float64\n",
            " 6   attribute_7   208 non-null    float64\n",
            " 7   attribute_8   208 non-null    float64\n",
            " 8   attribute_9   208 non-null    float64\n",
            " 9   attribute_10  208 non-null    float64\n",
            " 10  attribute_11  208 non-null    float64\n",
            " 11  attribute_12  208 non-null    float64\n",
            " 12  attribute_13  208 non-null    float64\n",
            " 13  attribute_14  208 non-null    float64\n",
            " 14  attribute_15  208 non-null    float64\n",
            " 15  attribute_16  208 non-null    float64\n",
            " 16  attribute_17  208 non-null    float64\n",
            " 17  attribute_18  208 non-null    float64\n",
            " 18  attribute_19  208 non-null    float64\n",
            " 19  attribute_20  208 non-null    float64\n",
            " 20  attribute_21  208 non-null    float64\n",
            " 21  attribute_22  208 non-null    float64\n",
            " 22  attribute_23  208 non-null    float64\n",
            " 23  attribute_24  208 non-null    float64\n",
            " 24  attribute_25  208 non-null    float64\n",
            " 25  attribute_26  208 non-null    float64\n",
            " 26  attribute_27  208 non-null    float64\n",
            " 27  attribute_28  208 non-null    float64\n",
            " 28  attribute_29  208 non-null    float64\n",
            " 29  attribute_30  208 non-null    float64\n",
            " 30  attribute_31  208 non-null    float64\n",
            " 31  attribute_32  208 non-null    float64\n",
            " 32  attribute_33  208 non-null    float64\n",
            " 33  attribute_34  208 non-null    float64\n",
            " 34  attribute_35  208 non-null    float64\n",
            " 35  attribute_36  208 non-null    float64\n",
            " 36  attribute_37  208 non-null    float64\n",
            " 37  attribute_38  208 non-null    float64\n",
            " 38  attribute_39  208 non-null    float64\n",
            " 39  attribute_40  208 non-null    float64\n",
            " 40  attribute_41  208 non-null    float64\n",
            " 41  attribute_42  208 non-null    float64\n",
            " 42  attribute_43  208 non-null    float64\n",
            " 43  attribute_44  208 non-null    float64\n",
            " 44  attribute_45  208 non-null    float64\n",
            " 45  attribute_46  208 non-null    float64\n",
            " 46  attribute_47  208 non-null    float64\n",
            " 47  attribute_48  208 non-null    float64\n",
            " 48  attribute_49  208 non-null    float64\n",
            " 49  attribute_50  208 non-null    float64\n",
            " 50  attribute_51  208 non-null    float64\n",
            " 51  attribute_52  208 non-null    float64\n",
            " 52  attribute_53  208 non-null    float64\n",
            " 53  attribute_54  208 non-null    float64\n",
            " 54  attribute_55  208 non-null    float64\n",
            " 55  attribute_56  208 non-null    float64\n",
            " 56  attribute_57  208 non-null    float64\n",
            " 57  attribute_58  208 non-null    float64\n",
            " 58  attribute_59  208 non-null    float64\n",
            " 59  attribute_60  208 non-null    float64\n",
            " 60  Class         208 non-null    object \n",
            " 61  batch         208 non-null    object \n",
            " 62  location      208 non-null    object \n",
            "dtypes: float64(60), object(3)\n",
            "memory usage: 102.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNq-OW3fhdhR"
      },
      "source": [
        "As this dataset does not have any missings, we will introduce some random missings such that we are forced to make use of more sklearn preprocessing functionalities."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2\n",
        "Replace a random 10% of the dataframe by missing values."
      ],
      "metadata": {
        "id": "k1gh5cTuQhWA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLXEDvVshcxq",
        "outputId": "a45c9a08-60a2-4fbe-c548-71dc655ff4eb"
      },
      "source": [
        "# answer Q2\n",
        "np.random.seed(42)\n",
        "mask = np.random.choice([True, False], p=[0.1, 0.9], size=df.shape)\n",
        "mask"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False,  True,  True],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "vnZ-wmdXiyRE",
        "outputId": "779b03f9-cd6c-4e43-cf88-c9aab7d15cc7"
      },
      "source": [
        "# answer Q2 continued\n",
        "# replace original df:\n",
        "df = df.mask(mask)\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6a2cdebe-c490-4ec7-80f4-3c3ed9296332\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>...</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>Class</th>\n",
              "      <th>batch</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 63 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a2cdebe-c490-4ec7-80f4-3c3ed9296332')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a2cdebe-c490-4ec7-80f4-3c3ed9296332 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a2cdebe-c490-4ec7-80f4-3c3ed9296332');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
              "0       0.0200       0.0371       0.0428       0.0207       0.0954   \n",
              "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
              "2       0.0262       0.0582          NaN       0.1083       0.0974   \n",
              "3       0.0100          NaN       0.0623       0.0205       0.0205   \n",
              "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
              "\n",
              "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
              "0       0.0986          NaN       0.1601       0.3109        0.2111  ...   \n",
              "1          NaN       0.2156       0.3481       0.3337           NaN  ...   \n",
              "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
              "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
              "4       0.0649       0.1209          NaN       0.3564        0.4459  ...   \n",
              "\n",
              "   attribute_54  attribute_55  attribute_56  attribute_57  attribute_58  \\\n",
              "0        0.0159        0.0072        0.0167           NaN        0.0084   \n",
              "1        0.0048        0.0094        0.0191        0.0140        0.0049   \n",
              "2        0.0095        0.0180        0.0244        0.0316        0.0164   \n",
              "3        0.0150        0.0085           NaN        0.0050        0.0044   \n",
              "4        0.0105        0.0110        0.0015        0.0072        0.0048   \n",
              "\n",
              "   attribute_59  attribute_60  Class  batch  location  \n",
              "0           NaN        0.0032   Rock  first     loc_A  \n",
              "1        0.0052        0.0044   Rock  first     loc_A  \n",
              "2        0.0095        0.0078   Rock  first     loc_A  \n",
              "3        0.0040        0.0117   Rock  first     loc_A  \n",
              "4        0.0107           NaN    NaN  first     loc_A  \n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp4yf_SIjN8L"
      },
      "source": [
        "The next step is to split the data into a random train (70%) and test (30%) set, such that we can perform model selection in the next section on the train set, and finally perform model assessment on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDRA7xvD_HUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "95cdd3ea-ff09-4991-aa83-c6e58987ade8"
      },
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in split.split(df, df['Class']):\n",
        "  strat_train_set = df.loc[train_index]\n",
        "  strat_test_set = df.loc[test_index]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2d45184db8a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mstrat_train_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mstrat_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \"\"\"\n\u001b[0;32m-> 2022\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2023\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input contains NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGRVlbzbnceO"
      },
      "source": [
        "This is not working due to missings in the outcome variable, which causes StratifiedShuffleSplit to fail, because we ask it to perform a split where the distribution of our outcome variable Class is comparable across both the train and test set. And when the outcome variable Class contains missings, that procedure fails.\n",
        "\n",
        "This puts us in a Catch 22: we cannot impute the outcome variable using only the training data on outcomes, as our training data has to be defined based on our outcome variable. Please note this will not be a problem when the split between train and test data is not done randomly, but rather based on time, or location. In our case, however, it is a problem, and this is typically the point where you check whether the missing outcome data can be retrieved through other means, where you decide to drop missings, or decide to impute the outcome data. \n",
        "\n",
        "For now we will impute the missing *outcome* values with the most occurring value, and use the preprocessing functionality of sklearn for this task. We will use this functionality again after splitting the data to impute missings in the *predictors*, as this will ensure that we do the exact same preprocessing on the predictors in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "Missings in the outcome variable are more problematic than missings in the predictor variables. \n",
        "- Why is this the case? \n",
        "- What are the potential downsides of imputing the outcome variable?\n",
        "- What are the potential downsides of removing instances with missing outcome data?"
      ],
      "metadata": {
        "id": "7Wm9pxTaWX6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For now we take a simple approach and impute the missing outcome values with the most frequent class."
      ],
      "metadata": {
        "id": "bXydj9EuXR_s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTpgvSAHpgGE",
        "outputId": "40a8b23b-1c51-441b-8656-874a7466d6f7"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp_outcome = SimpleImputer(strategy = 'most_frequent')\n",
        "imp_outcome.fit(df['Class'].to_frame())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleImputer(strategy='most_frequent')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrG_BLhQvv9I"
      },
      "source": [
        "The code above created an 'impute object' that has been fitted on df['Class'] to determine what the imputation value should be. The outcome Class has not been 'transformed' yet, and so it will still contain missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7hTPYk9wTAb",
        "outputId": "a1742010-c0e6-474b-aa6a-cf83e08010d2"
      },
      "source": [
        "sum(df['Class'].isnull())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value that will be imputed when using the impute object to transform a variable, is saved in *.statistics_*, as shown below (and equals 'Mine', which is indeed the most_frequent value in df['Class'])."
      ],
      "metadata": {
        "id": "LuUL39-Ho5kD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBLqHSvLuqc9",
        "outputId": "b69a327b-3f4b-4b03-d5a3-cfeaaf87d04b"
      },
      "source": [
        "imp_outcome.statistics_"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mine'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The current distribution of df['Class'] is:"
      ],
      "metadata": {
        "id": "3tzc3DEgqJ9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDO7YbX4qIqq",
        "outputId": "77cdfd0b-9c8d-4729-d1c7-052291df861e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mine    101\n",
              "Rock     92\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMp1CLAxwF9B"
      },
      "source": [
        "We now impute the missing values of df['Class'] by applying 'transform' on df['Class']."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yhQtbMMwd0n",
        "outputId": "c6d419da-9098-47f2-f2e4-823a40199984"
      },
      "source": [
        "df['Class'] = imp_outcome.transform(df['Class'].to_frame())\n",
        "sum(df['Class'].isnull())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQODfNSnql2l",
        "outputId": "17190480-d8b5-40cd-90e7-83e76d36052a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mine    116\n",
              "Rock     92\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euxwb1lpws8h"
      },
      "source": [
        "We could have done both the fitting and transforming in one go using the command imp_outcome.fit_transform().\n",
        "\n",
        "We are now ready to proceed with splitting the data into a train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LlSGNPzw0t0"
      },
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in split.split(df, df['Class']):\n",
        "  strat_train_set = df.loc[train_index]\n",
        "  strat_test_set = df.loc[test_index]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5t8ibImAlV3",
        "outputId": "3084dc1b-eeaf-4fd0-9fa0-6b9901bc3b6e"
      },
      "source": [
        "print('share of observations in the train set:', str(round(len(strat_train_set)/len(df), 3)))\n",
        "print('share of observations in the test set:', str(round(len(strat_test_set)/len(df), 3)))\n",
        "print('share of mines in the train set:', str(round(len(strat_train_set.loc[strat_train_set['Class'] == 'Mine'])/len(strat_train_set), 3)))\n",
        "print('share of mines in the test set:', str(round(len(strat_test_set.loc[strat_test_set['Class'] == 'Mine'])/len(strat_test_set), 3)))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "share of observations in the train set: 0.697\n",
            "share of observations in the test set: 0.303\n",
            "share of mines in the train set: 0.559\n",
            "share of mines in the test set: 0.556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now split the features from the outcome data for both the train and the test set, to align with the input needed when using sklearn to train models."
      ],
      "metadata": {
        "id": "hLEYothCqyTt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSqWxbi24D5v"
      },
      "source": [
        "# split features and outcome data\n",
        "X_train = strat_train_set.loc[:,strat_train_set.columns != 'Class']\n",
        "y_train = strat_train_set['Class']\n",
        "X_test = strat_test_set.loc[:,strat_test_set.columns != 'Class']\n",
        "y_test = strat_test_set['Class']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wASW59mlxHa2"
      },
      "source": [
        "## Setting up the pipeline\n",
        "\n",
        "Machine learning is about trial and error, with typically many iterations between different ways to prepare the data (data preparation) and assessing how that translates into performance (model building).\n",
        "\n",
        "Going through different iterations should require the least possible effort, which is done by setting up a pipeline, using sklearn's pipeline functionality. A pipeline explicitly operationalizes all the different steps to get from raw data into data prepared and ready to serve as modeling input.\n",
        "\n",
        "\n",
        "As such, the pipeline serves multiple purposes: \n",
        "- it encompasses every preprocessing step, coded within an overarching Python object, such that new data is really easy to preprocess consistently (the raw test data or tomorrow's raw process data). This approach prevents 'manual' adjustments to the data, that would get lost or would need to be repeated 'manually' when preparing new data; \n",
        "- it makes it really easy to tweak the preprocessing steps, trying out different ways to prepare the data, requiring minimal adjustment to your code (less time-consuming and less error-prone);\n",
        "- it helps in preventing mistakes that contribute to data leakage.\n",
        "\n",
        "Typical preprocessing steps captured in a pipeline include:\n",
        "- selecting the variables\n",
        "- imputing missing values\n",
        "- scaling numeric variables\n",
        "- creating dummy variables for categorical variables\n",
        "\n",
        "On top of that, there is full flexibility in defining your own preprocessing steps within a pipeline.\n",
        "\n",
        "Below, we will set up the typical pipeline step-by-step. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZHs9z1IHwi7"
      },
      "source": [
        "The first thing to realize is that numeric and categorical features require different preprocessing steps, effectively meaning that our overarching pipeline should contain two parallel pipelines: one for preparing numeric features and one for preparing categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZS8TNN8Im9V",
        "outputId": "83bdd588-9faa-4d8c-df84-d2078dac57e0"
      },
      "source": [
        "# dividing the features into numeric and non-numeric\n",
        "num_features = X_train.select_dtypes(include=['float']).columns\n",
        "cat_features = X_train.select_dtypes(exclude=['float']).columns\n",
        "print(num_features)\n",
        "print(cat_features)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['attribute_1', 'attribute_2', 'attribute_3', 'attribute_4',\n",
            "       'attribute_5', 'attribute_6', 'attribute_7', 'attribute_8',\n",
            "       'attribute_9', 'attribute_10', 'attribute_11', 'attribute_12',\n",
            "       'attribute_13', 'attribute_14', 'attribute_15', 'attribute_16',\n",
            "       'attribute_17', 'attribute_18', 'attribute_19', 'attribute_20',\n",
            "       'attribute_21', 'attribute_22', 'attribute_23', 'attribute_24',\n",
            "       'attribute_25', 'attribute_26', 'attribute_27', 'attribute_28',\n",
            "       'attribute_29', 'attribute_30', 'attribute_31', 'attribute_32',\n",
            "       'attribute_33', 'attribute_34', 'attribute_35', 'attribute_36',\n",
            "       'attribute_37', 'attribute_38', 'attribute_39', 'attribute_40',\n",
            "       'attribute_41', 'attribute_42', 'attribute_43', 'attribute_44',\n",
            "       'attribute_45', 'attribute_46', 'attribute_47', 'attribute_48',\n",
            "       'attribute_49', 'attribute_50', 'attribute_51', 'attribute_52',\n",
            "       'attribute_53', 'attribute_54', 'attribute_55', 'attribute_56',\n",
            "       'attribute_57', 'attribute_58', 'attribute_59', 'attribute_60'],\n",
            "      dtype='object')\n",
            "Index(['batch', 'location'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMVKvJXELD41"
      },
      "source": [
        "We will now define a 'numeric pipeline' and a 'categorical pipeline', which is then combined into a 'full pipeline'.\n",
        "\n",
        "We start off with the 'numeric pipeline', containing the steps of imputing missing values, and standardizing the feature values (which is required for some machine learning algorithms, and speeds up estimation for others). As the imputation strategy within the numeric pipeline only applies to numeric features, imputation can be straightforwardly applied using median imputation (or comparable methods)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37CxIKPVMT5B"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4\n",
        "- make a copy of the dataframe (df_tmp = df.copy())\n",
        "- fit the SimpleImputer based on median values on the numeric features\n",
        "- fit a StandardScaler on the numeric features\n",
        "- check the fitted statistics of both objects"
      ],
      "metadata": {
        "id": "iMF_u1Ce0_C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answer Q4\n",
        "df_tmp = df.copy()\n",
        "imp_nums = SimpleImputer(strategy = 'median')\n",
        "imp_nums.fit(df_tmp[num_features])\n",
        "\n",
        "sc_nums = StandardScaler()\n",
        "sc_nums.fit(df_tmp[num_features])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9lg2yh-3RfG",
        "outputId": "bc25a709-8197-4fc7-a8c3-70093e41e2a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer Q4 continued\n",
        "imp_nums.statistics_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQXeAk3V4Ew5",
        "outputId": "af158866-9790-4c36-e83f-9f0749950431"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02285, 0.0308 , 0.0344 , 0.0445 , 0.0597 , 0.08885, 0.10695,\n",
              "       0.1119 , 0.15375, 0.185  , 0.23275, 0.2555 , 0.2656 , 0.2821 ,\n",
              "       0.2885 , 0.2956 , 0.31   , 0.36535, 0.4416 , 0.5448 , 0.6177 ,\n",
              "       0.6689 , 0.6987 , 0.6954 , 0.7221 , 0.7511 , 0.7552 , 0.7319 ,\n",
              "       0.679  , 0.6152 , 0.492  , 0.4289 , 0.39375, 0.3776 , 0.3032 ,\n",
              "       0.3043 , 0.2934 , 0.315  , 0.2736 , 0.2811 , 0.258  , 0.2546 ,\n",
              "       0.22255, 0.17715, 0.1459 , 0.12435, 0.09905, 0.0787 , 0.0447 ,\n",
              "       0.01765, 0.0139 , 0.01165, 0.00935, 0.0093 , 0.0075 , 0.0068 ,\n",
              "       0.00575, 0.00595, 0.0067 , 0.0051 ])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer Q4 continued\n",
        "# the statistics of the standardscaler are the mean and std\n",
        "print(sc_nums.mean_)\n",
        "print(sc_nums.scale_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8128w0v5YGM",
        "outputId": "5e229ea0-7da1-424b-fa3d-5ba1535bc07e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.02981848 0.03900267 0.04495916 0.05550309 0.07267322 0.10047083\n",
            " 0.12278895 0.13432703 0.17985426 0.21186383 0.24066505 0.25461421\n",
            " 0.27646117 0.29873602 0.32655319 0.36989577 0.42186919 0.44871359\n",
            " 0.50622383 0.56435167 0.60795105 0.62547423 0.6477306  0.67586021\n",
            " 0.67348883 0.6966328  0.70566402 0.69236978 0.63819686 0.58505714\n",
            " 0.50554545 0.43943825 0.41847819 0.40936021 0.38176292 0.38007906\n",
            " 0.35844375 0.343875   0.32421148 0.3162884  0.28658698 0.28599676\n",
            " 0.24733526 0.21202344 0.18910335 0.16432527 0.12248    0.09246979\n",
            " 0.05258617 0.01997581 0.01637722 0.01364158 0.01048021 0.01082434\n",
            " 0.00924513 0.00823194 0.00786868 0.00814946 0.00824064 0.00595955]\n",
            "[0.02388212 0.03375822 0.0390138  0.04744442 0.05391535 0.05171558\n",
            " 0.06274879 0.08428762 0.11824461 0.13874544 0.13344632 0.14184468\n",
            " 0.13699275 0.16576797 0.20392106 0.22907284 0.26981026 0.25711721\n",
            " 0.25495359 0.26336943 0.25676953 0.25897107 0.25142398 0.24095289\n",
            " 0.24435109 0.23467517 0.24413179 0.23925971 0.24156473 0.21479436\n",
            " 0.21804943 0.21239166 0.2045421  0.23581911 0.25657947 0.26728766\n",
            " 0.23838468 0.21586302 0.20183402 0.18176583 0.16825679 0.17019579\n",
            " 0.14060279 0.1339775  0.15019827 0.13532306 0.09000435 0.06344556\n",
            " 0.03676527 0.0133544  0.01256312 0.00982876 0.00690664 0.00705787\n",
            " 0.00669117 0.00578903 0.00601864 0.00661801 0.00632945 0.00417866]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WUPiNCQiNSg"
      },
      "source": [
        "### Unpacking the pipeline\n",
        "\n",
        "Let's now unpack this part of our pipeline:\n",
        "num_pipeline is now a Pipeline object, which, as you would expect, simply passes on the input it receives through each of the elements of the pipeline. Each element of the Pipeline uses the output of the previous step as its input.\n",
        "\n",
        "Each element is given a user-defined name, and is accompanied by a specific preprocessing step, which is often a function imported from the sklearn.preprocessing module, but could also be a user-defined function. Each element in the Pipeline can be accessed individually, as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAEEojV_jOsT",
        "outputId": "35a7a479-5a4c-4762-fe4a-f8387a0dfd3b"
      },
      "source": [
        "type(num_pipeline)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.pipeline.Pipeline"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRm6zA5GjSL3",
        "outputId": "af264853-0fe6-4292-98cb-1a7c8599d362"
      },
      "source": [
        "num_pipeline"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
              "                ('std_scaler', StandardScaler())])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX9gCmSHjXwc"
      },
      "source": [
        "Each functionality can be accessed individually as follows:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSPircvQkApB",
        "outputId": "3138b23d-815e-4525-9512-60ede761d126"
      },
      "source": [
        "num_pipeline['imputer']"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleImputer(strategy='median')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg88owwjkMAX"
      },
      "source": [
        "Just as we saw above, this preprocessing functionality can be used to transform data, but it needs to be fitted on data first (or it can be done simultaneously). Once we fit the num_pipeline to our numerical training data, it will contain medians to be imputed and scaling factors to be applied, making it possible to use the pipeline for transforming data according to these preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "gncOglbakGLs",
        "outputId": "eebe528f-280f-4f05-cb9e-26186edd5d19"
      },
      "source": [
        "# transforming will give an error, until the pipeline is being fitted (as stated in the NotFittedError below)\n",
        "num_pipeline.transform(X_train[num_features])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5025c0c2f778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transforming will give an error, until the pipeline is being fitted (as stated in the NotFittedError below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mX\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mimputed\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \"\"\"\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This SimpleImputer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCJwS0ZymbWe",
        "outputId": "9d00e2ed-d71a-4061-8301-40d64675ad86"
      },
      "source": [
        "num_pipeline.fit(X_train[num_features])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
              "                ('std_scaler', StandardScaler())])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icqwGekRmnzi"
      },
      "source": [
        "Now the imputer and standard scaler do contain fitted statistics that can be applied to transform data according to these preprocessing steps. These statistics can be accessed by going into the pipeline object, to the specific pipeline elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Yl6EGVmhep",
        "outputId": "a6ce7842-1e2e-4cea-d5ed-6d9e727699f2"
      },
      "source": [
        "# the statistics_ for the imputer step contains the medians to be used for imputation\n",
        "num_pipeline['imputer'].statistics_"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0228 , 0.02925, 0.038  , 0.0454 , 0.06105, 0.0932 , 0.1122 ,\n",
              "       0.113  , 0.1553 , 0.18705, 0.2373 , 0.2551 , 0.27065, 0.2976 ,\n",
              "       0.3039 , 0.3047 , 0.3068 , 0.3771 , 0.4433 , 0.5425 , 0.6496 ,\n",
              "       0.6628 , 0.7052 , 0.69325, 0.72775, 0.7545 , 0.7654 , 0.7321 ,\n",
              "       0.634  , 0.6005 , 0.492  , 0.4241 , 0.3897 , 0.3682 , 0.3369 ,\n",
              "       0.31035, 0.2821 , 0.315  , 0.28905, 0.2883 , 0.2609 , 0.2633 ,\n",
              "       0.2207 , 0.1755 , 0.14955, 0.12785, 0.0947 , 0.08055, 0.049  ,\n",
              "       0.0179 , 0.014  , 0.0115 , 0.00865, 0.0093 , 0.0075 , 0.0065 ,\n",
              "       0.0057 , 0.0058 , 0.0069 , 0.0048 ])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xKEQwyBinPPh",
        "outputId": "53f369cf-4ad6-46fd-99ca-1b3acddfa741"
      },
      "source": [
        "# the statistics of the standardscaler are the mean and std\n",
        "means = num_pipeline['std_scaler'].mean_\n",
        "scale = num_pipeline['std_scaler'].scale_\n",
        "pd.DataFrame({'Means':means, 'Scale':scale}, index=X_train[num_features].columns)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-21c607ec-f167-4638-a574-11d7de2624bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Means</th>\n",
              "      <th>Scale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>attribute_1</th>\n",
              "      <td>0.030316</td>\n",
              "      <td>0.024040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_2</th>\n",
              "      <td>0.038669</td>\n",
              "      <td>0.035053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_3</th>\n",
              "      <td>0.047230</td>\n",
              "      <td>0.041599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_4</th>\n",
              "      <td>0.057621</td>\n",
              "      <td>0.050468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_5</th>\n",
              "      <td>0.074851</td>\n",
              "      <td>0.055196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_6</th>\n",
              "      <td>0.101849</td>\n",
              "      <td>0.048008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_7</th>\n",
              "      <td>0.126627</td>\n",
              "      <td>0.063411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_8</th>\n",
              "      <td>0.136208</td>\n",
              "      <td>0.085086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_9</th>\n",
              "      <td>0.183074</td>\n",
              "      <td>0.117458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_10</th>\n",
              "      <td>0.215243</td>\n",
              "      <td>0.135830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_11</th>\n",
              "      <td>0.248950</td>\n",
              "      <td>0.125070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_12</th>\n",
              "      <td>0.256374</td>\n",
              "      <td>0.132509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_13</th>\n",
              "      <td>0.283613</td>\n",
              "      <td>0.126429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_14</th>\n",
              "      <td>0.310881</td>\n",
              "      <td>0.160377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_15</th>\n",
              "      <td>0.341880</td>\n",
              "      <td>0.194530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_16</th>\n",
              "      <td>0.371477</td>\n",
              "      <td>0.222879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_17</th>\n",
              "      <td>0.418797</td>\n",
              "      <td>0.265304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_18</th>\n",
              "      <td>0.458043</td>\n",
              "      <td>0.254017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_19</th>\n",
              "      <td>0.505872</td>\n",
              "      <td>0.256024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_20</th>\n",
              "      <td>0.555277</td>\n",
              "      <td>0.248828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_21</th>\n",
              "      <td>0.609820</td>\n",
              "      <td>0.247246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_22</th>\n",
              "      <td>0.624209</td>\n",
              "      <td>0.251237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_23</th>\n",
              "      <td>0.654730</td>\n",
              "      <td>0.238628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_24</th>\n",
              "      <td>0.678239</td>\n",
              "      <td>0.229609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_25</th>\n",
              "      <td>0.682419</td>\n",
              "      <td>0.229040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_26</th>\n",
              "      <td>0.712124</td>\n",
              "      <td>0.224476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_27</th>\n",
              "      <td>0.723590</td>\n",
              "      <td>0.226149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_28</th>\n",
              "      <td>0.700014</td>\n",
              "      <td>0.215167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_29</th>\n",
              "      <td>0.630289</td>\n",
              "      <td>0.231767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_30</th>\n",
              "      <td>0.580569</td>\n",
              "      <td>0.199783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_31</th>\n",
              "      <td>0.505533</td>\n",
              "      <td>0.201870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_32</th>\n",
              "      <td>0.434770</td>\n",
              "      <td>0.203157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_33</th>\n",
              "      <td>0.412819</td>\n",
              "      <td>0.196230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_34</th>\n",
              "      <td>0.396540</td>\n",
              "      <td>0.221638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_35</th>\n",
              "      <td>0.368626</td>\n",
              "      <td>0.225584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_36</th>\n",
              "      <td>0.373233</td>\n",
              "      <td>0.255737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_37</th>\n",
              "      <td>0.349441</td>\n",
              "      <td>0.235093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_38</th>\n",
              "      <td>0.345731</td>\n",
              "      <td>0.211585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_39</th>\n",
              "      <td>0.322130</td>\n",
              "      <td>0.187913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_40</th>\n",
              "      <td>0.314211</td>\n",
              "      <td>0.168741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_41</th>\n",
              "      <td>0.292407</td>\n",
              "      <td>0.159929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_42</th>\n",
              "      <td>0.283801</td>\n",
              "      <td>0.161344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_43</th>\n",
              "      <td>0.243272</td>\n",
              "      <td>0.132807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_44</th>\n",
              "      <td>0.210315</td>\n",
              "      <td>0.129146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_45</th>\n",
              "      <td>0.186814</td>\n",
              "      <td>0.144599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_46</th>\n",
              "      <td>0.161016</td>\n",
              "      <td>0.126471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_47</th>\n",
              "      <td>0.117938</td>\n",
              "      <td>0.086613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_48</th>\n",
              "      <td>0.093636</td>\n",
              "      <td>0.063992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_49</th>\n",
              "      <td>0.054905</td>\n",
              "      <td>0.036116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_50</th>\n",
              "      <td>0.020219</td>\n",
              "      <td>0.012895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_51</th>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.011761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_52</th>\n",
              "      <td>0.013355</td>\n",
              "      <td>0.009462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_53</th>\n",
              "      <td>0.009907</td>\n",
              "      <td>0.006221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_54</th>\n",
              "      <td>0.010981</td>\n",
              "      <td>0.007202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_55</th>\n",
              "      <td>0.009450</td>\n",
              "      <td>0.007024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_56</th>\n",
              "      <td>0.007970</td>\n",
              "      <td>0.005882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_57</th>\n",
              "      <td>0.007569</td>\n",
              "      <td>0.005725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_58</th>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.006671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_59</th>\n",
              "      <td>0.008344</td>\n",
              "      <td>0.006434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_60</th>\n",
              "      <td>0.005890</td>\n",
              "      <td>0.004134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21c607ec-f167-4638-a574-11d7de2624bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21c607ec-f167-4638-a574-11d7de2624bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21c607ec-f167-4638-a574-11d7de2624bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 Means     Scale\n",
              "attribute_1   0.030316  0.024040\n",
              "attribute_2   0.038669  0.035053\n",
              "attribute_3   0.047230  0.041599\n",
              "attribute_4   0.057621  0.050468\n",
              "attribute_5   0.074851  0.055196\n",
              "attribute_6   0.101849  0.048008\n",
              "attribute_7   0.126627  0.063411\n",
              "attribute_8   0.136208  0.085086\n",
              "attribute_9   0.183074  0.117458\n",
              "attribute_10  0.215243  0.135830\n",
              "attribute_11  0.248950  0.125070\n",
              "attribute_12  0.256374  0.132509\n",
              "attribute_13  0.283613  0.126429\n",
              "attribute_14  0.310881  0.160377\n",
              "attribute_15  0.341880  0.194530\n",
              "attribute_16  0.371477  0.222879\n",
              "attribute_17  0.418797  0.265304\n",
              "attribute_18  0.458043  0.254017\n",
              "attribute_19  0.505872  0.256024\n",
              "attribute_20  0.555277  0.248828\n",
              "attribute_21  0.609820  0.247246\n",
              "attribute_22  0.624209  0.251237\n",
              "attribute_23  0.654730  0.238628\n",
              "attribute_24  0.678239  0.229609\n",
              "attribute_25  0.682419  0.229040\n",
              "attribute_26  0.712124  0.224476\n",
              "attribute_27  0.723590  0.226149\n",
              "attribute_28  0.700014  0.215167\n",
              "attribute_29  0.630289  0.231767\n",
              "attribute_30  0.580569  0.199783\n",
              "attribute_31  0.505533  0.201870\n",
              "attribute_32  0.434770  0.203157\n",
              "attribute_33  0.412819  0.196230\n",
              "attribute_34  0.396540  0.221638\n",
              "attribute_35  0.368626  0.225584\n",
              "attribute_36  0.373233  0.255737\n",
              "attribute_37  0.349441  0.235093\n",
              "attribute_38  0.345731  0.211585\n",
              "attribute_39  0.322130  0.187913\n",
              "attribute_40  0.314211  0.168741\n",
              "attribute_41  0.292407  0.159929\n",
              "attribute_42  0.283801  0.161344\n",
              "attribute_43  0.243272  0.132807\n",
              "attribute_44  0.210315  0.129146\n",
              "attribute_45  0.186814  0.144599\n",
              "attribute_46  0.161016  0.126471\n",
              "attribute_47  0.117938  0.086613\n",
              "attribute_48  0.093636  0.063992\n",
              "attribute_49  0.054905  0.036116\n",
              "attribute_50  0.020219  0.012895\n",
              "attribute_51  0.015806  0.011761\n",
              "attribute_52  0.013355  0.009462\n",
              "attribute_53  0.009907  0.006221\n",
              "attribute_54  0.010981  0.007202\n",
              "attribute_55  0.009450  0.007024\n",
              "attribute_56  0.007970  0.005882\n",
              "attribute_57  0.007569  0.005725\n",
              "attribute_58  0.007968  0.006671\n",
              "attribute_59  0.008344  0.006434\n",
              "attribute_60  0.005890  0.004134"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "Compare the imputer and scaler statistics found here with the statistics found under question 4. Explain any differences."
      ],
      "metadata": {
        "id": "di7-9vZB7XIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Q5: \n",
        "- first of all these preprocessing steps were applied to different datasets.\n",
        "- more subtly, even if we do use the same dataset, the mean and scale statistics would still be different, as the pipeline takes as input the data that results from having done the previous preprocessing steps in that same pipeline (i.e. medians have been added, altering the means and scales)."
      ],
      "metadata": {
        "id": "l0SdRyqU7_VS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsfsHJnOqyfH"
      },
      "source": [
        "Now that the imputer and standard scaler have been fitted, we can use it to transform the numerical train data, and check whether it indeed results in fully imputed, fully standarized data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIKbhWjPrOtw",
        "outputId": "76ab25d7-8e87-4aba-f9cc-9b651d30a17d"
      },
      "source": [
        "X_num_prep = num_pipeline.transform(X_train[num_features])\n",
        "X_num_prep"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.92694488,  0.50297168,  1.79499411, ...,  0.34962688,\n",
              "         4.36066979,  3.60663451],\n",
              "       [-0.13792866, -0.63815596, -0.31562267, ...,  0.21471763,\n",
              "         0.33508158,  0.82479305],\n",
              "       [-0.18784461,  0.1321052 ,  0.17957899, ..., -0.24996978,\n",
              "        -0.55085868, -0.21537375],\n",
              "       ...,\n",
              "       [-0.30847482, -0.05047522, -1.03919403, ..., -0.75962693,\n",
              "         0.31953877, -0.2637536 ],\n",
              "       [-0.74939902, -1.04040346, -0.66418695, ..., -0.32491936,\n",
              "        -0.56640149,  0.29261469],\n",
              "       [-0.88666787, -0.92629069, -0.2218709 , ..., -0.39986894,\n",
              "         1.64067776, -0.2637536 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPTO8StNr2Rm"
      },
      "source": [
        "You see that the pipeline has the typically undesired feature (though it does speed up computing time) of removing the column names. It is good practice to keep track of the column names, which becomes even more important when we apply preprocessing steps that will change the number of features that we have, as we will encounter when preprocessing the categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "m5JAka5EtEIr",
        "outputId": "8b526723-66f2-4e0f-e35a-c6009ff7f892"
      },
      "source": [
        "X_num_prep = pd.DataFrame(X_num_prep, columns=X_train[num_features].columns)\n",
        "X_num_prep.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4758569d-300f-4941-8d9f-c672d87efc80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>...</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.926945</td>\n",
              "      <td>0.502972</td>\n",
              "      <td>1.794994</td>\n",
              "      <td>1.247895</td>\n",
              "      <td>-0.910411</td>\n",
              "      <td>0.007312</td>\n",
              "      <td>-0.227513</td>\n",
              "      <td>-1.084874</td>\n",
              "      <td>0.391854</td>\n",
              "      <td>-0.383149</td>\n",
              "      <td>...</td>\n",
              "      <td>1.887135</td>\n",
              "      <td>2.171228</td>\n",
              "      <td>0.802669</td>\n",
              "      <td>3.127028</td>\n",
              "      <td>4.007493</td>\n",
              "      <td>1.603111</td>\n",
              "      <td>0.983535</td>\n",
              "      <td>0.349627</td>\n",
              "      <td>4.360670</td>\n",
              "      <td>3.606635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.137929</td>\n",
              "      <td>-0.638156</td>\n",
              "      <td>-0.315623</td>\n",
              "      <td>-0.652323</td>\n",
              "      <td>0.133136</td>\n",
              "      <td>0.494733</td>\n",
              "      <td>0.089465</td>\n",
              "      <td>0.260823</td>\n",
              "      <td>0.158578</td>\n",
              "      <td>-0.022404</td>\n",
              "      <td>...</td>\n",
              "      <td>0.331137</td>\n",
              "      <td>-0.196059</td>\n",
              "      <td>1.686764</td>\n",
              "      <td>-0.344468</td>\n",
              "      <td>-0.733223</td>\n",
              "      <td>0.209051</td>\n",
              "      <td>1.088333</td>\n",
              "      <td>0.214718</td>\n",
              "      <td>0.335082</td>\n",
              "      <td>0.824793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.187845</td>\n",
              "      <td>0.132105</td>\n",
              "      <td>0.179579</td>\n",
              "      <td>0.207629</td>\n",
              "      <td>-0.250042</td>\n",
              "      <td>0.482235</td>\n",
              "      <td>0.046886</td>\n",
              "      <td>0.431239</td>\n",
              "      <td>0.820094</td>\n",
              "      <td>0.590127</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.315070</td>\n",
              "      <td>-0.449697</td>\n",
              "      <td>-0.595808</td>\n",
              "      <td>-1.260943</td>\n",
              "      <td>-0.277659</td>\n",
              "      <td>-0.249970</td>\n",
              "      <td>-0.780564</td>\n",
              "      <td>-0.249970</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.215374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.778517</td>\n",
              "      <td>-0.592511</td>\n",
              "      <td>-0.056002</td>\n",
              "      <td>1.029934</td>\n",
              "      <td>2.109716</td>\n",
              "      <td>-0.196821</td>\n",
              "      <td>-0.796811</td>\n",
              "      <td>-0.317415</td>\n",
              "      <td>-0.914150</td>\n",
              "      <td>-0.844020</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.080315</td>\n",
              "      <td>0.311217</td>\n",
              "      <td>-0.001053</td>\n",
              "      <td>-0.358354</td>\n",
              "      <td>2.498437</td>\n",
              "      <td>3.354188</td>\n",
              "      <td>0.372213</td>\n",
              "      <td>-0.384879</td>\n",
              "      <td>-0.224460</td>\n",
              "      <td>0.800603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.587172</td>\n",
              "      <td>-0.381402</td>\n",
              "      <td>-0.505530</td>\n",
              "      <td>-0.376901</td>\n",
              "      <td>-0.187537</td>\n",
              "      <td>-1.138334</td>\n",
              "      <td>-0.331595</td>\n",
              "      <td>0.030468</td>\n",
              "      <td>-0.236458</td>\n",
              "      <td>-0.602542</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.179026</td>\n",
              "      <td>-0.661062</td>\n",
              "      <td>-0.274319</td>\n",
              "      <td>1.696771</td>\n",
              "      <td>1.473417</td>\n",
              "      <td>-0.096963</td>\n",
              "      <td>-0.326440</td>\n",
              "      <td>0.304657</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.965261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 60 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4758569d-300f-4941-8d9f-c672d87efc80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4758569d-300f-4941-8d9f-c672d87efc80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4758569d-300f-4941-8d9f-c672d87efc80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
              "0     0.926945     0.502972     1.794994     1.247895    -0.910411   \n",
              "1    -0.137929    -0.638156    -0.315623    -0.652323     0.133136   \n",
              "2    -0.187845     0.132105     0.179579     0.207629    -0.250042   \n",
              "3    -0.778517    -0.592511    -0.056002     1.029934     2.109716   \n",
              "4    -0.587172    -0.381402    -0.505530    -0.376901    -0.187537   \n",
              "\n",
              "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
              "0     0.007312    -0.227513    -1.084874     0.391854     -0.383149  ...   \n",
              "1     0.494733     0.089465     0.260823     0.158578     -0.022404  ...   \n",
              "2     0.482235     0.046886     0.431239     0.820094      0.590127  ...   \n",
              "3    -0.196821    -0.796811    -0.317415    -0.914150     -0.844020  ...   \n",
              "4    -1.138334    -0.331595     0.030468    -0.236458     -0.602542  ...   \n",
              "\n",
              "   attribute_51  attribute_52  attribute_53  attribute_54  attribute_55  \\\n",
              "0      1.887135      2.171228      0.802669      3.127028      4.007493   \n",
              "1      0.331137     -0.196059      1.686764     -0.344468     -0.733223   \n",
              "2     -0.315070     -0.449697     -0.595808     -1.260943     -0.277659   \n",
              "3     -1.080315      0.311217     -0.001053     -0.358354      2.498437   \n",
              "4     -0.179026     -0.661062     -0.274319      1.696771      1.473417   \n",
              "\n",
              "   attribute_56  attribute_57  attribute_58  attribute_59  attribute_60  \n",
              "0      1.603111      0.983535      0.349627      4.360670      3.606635  \n",
              "1      0.209051      1.088333      0.214718      0.335082      0.824793  \n",
              "2     -0.249970     -0.780564     -0.249970     -0.550859     -0.215374  \n",
              "3      3.354188      0.372213     -0.384879     -0.224460      0.800603  \n",
              "4     -0.096963     -0.326440      0.304657     -0.550859     -0.965261  \n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "- check whether all missings have been imputed.\n",
        "- check whether means and standard deviations are 0 and 1 for each feature."
      ],
      "metadata": {
        "id": "UMl3VGCL9H5T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgqLIKxrtR16",
        "outputId": "329d7f32-32c8-4a94-c2f5-7994faa7abd6"
      },
      "source": [
        "# Answer Q6\n",
        "# every missing has been imputed\n",
        "sum(X_num_prep.isnull().sum())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R-FMfZb-tppr",
        "outputId": "5a03e6f6-3b03-45e9-dd0c-7aaa0df32482"
      },
      "source": [
        "# Answer Q6 - continued\n",
        "# every mean is 0; every standard deviation is 1\n",
        "mean = X_num_prep.mean(axis=0).round(3)\n",
        "std = X_num_prep.std(axis=0).round(3)\n",
        "pd.DataFrame({'Prepped_Means':mean, 'Prepped_Scale':std}, index=X_train[num_features].columns)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1a786caa-4de7-47db-97e0-3035310d7f29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prepped_Means</th>\n",
              "      <th>Prepped_Scale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>attribute_1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_6</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_7</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_8</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_9</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_13</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_14</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_18</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_20</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_23</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_24</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_25</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_28</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_30</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_32</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_33</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_34</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_35</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_36</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_37</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_38</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_39</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_41</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_42</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_43</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_44</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_45</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_46</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_47</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_48</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_49</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_50</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_51</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_52</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_53</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_54</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_55</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_56</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_57</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_58</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_59</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_60</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a786caa-4de7-47db-97e0-3035310d7f29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a786caa-4de7-47db-97e0-3035310d7f29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a786caa-4de7-47db-97e0-3035310d7f29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              Prepped_Means  Prepped_Scale\n",
              "attribute_1             0.0          1.003\n",
              "attribute_2             0.0          1.003\n",
              "attribute_3             0.0          1.003\n",
              "attribute_4             0.0          1.003\n",
              "attribute_5             0.0          1.003\n",
              "attribute_6            -0.0          1.003\n",
              "attribute_7            -0.0          1.003\n",
              "attribute_8            -0.0          1.003\n",
              "attribute_9            -0.0          1.003\n",
              "attribute_10            0.0          1.003\n",
              "attribute_11            0.0          1.003\n",
              "attribute_12            0.0          1.003\n",
              "attribute_13           -0.0          1.003\n",
              "attribute_14           -0.0          1.003\n",
              "attribute_15            0.0          1.003\n",
              "attribute_16            0.0          1.003\n",
              "attribute_17            0.0          1.003\n",
              "attribute_18           -0.0          1.003\n",
              "attribute_19            0.0          1.003\n",
              "attribute_20           -0.0          1.003\n",
              "attribute_21            0.0          1.003\n",
              "attribute_22            0.0          1.003\n",
              "attribute_23            0.0          1.003\n",
              "attribute_24           -0.0          1.003\n",
              "attribute_25            0.0          1.003\n",
              "attribute_26            0.0          1.003\n",
              "attribute_27            0.0          1.003\n",
              "attribute_28            0.0          1.003\n",
              "attribute_29            0.0          1.003\n",
              "attribute_30           -0.0          1.003\n",
              "attribute_31            0.0          1.003\n",
              "attribute_32           -0.0          1.003\n",
              "attribute_33           -0.0          1.003\n",
              "attribute_34           -0.0          1.003\n",
              "attribute_35           -0.0          1.003\n",
              "attribute_36            0.0          1.003\n",
              "attribute_37           -0.0          1.003\n",
              "attribute_38            0.0          1.003\n",
              "attribute_39            0.0          1.003\n",
              "attribute_40            0.0          1.003\n",
              "attribute_41            0.0          1.003\n",
              "attribute_42           -0.0          1.003\n",
              "attribute_43           -0.0          1.003\n",
              "attribute_44           -0.0          1.003\n",
              "attribute_45           -0.0          1.003\n",
              "attribute_46           -0.0          1.003\n",
              "attribute_47            0.0          1.003\n",
              "attribute_48            0.0          1.003\n",
              "attribute_49           -0.0          1.003\n",
              "attribute_50           -0.0          1.003\n",
              "attribute_51           -0.0          1.003\n",
              "attribute_52           -0.0          1.003\n",
              "attribute_53           -0.0          1.003\n",
              "attribute_54           -0.0          1.003\n",
              "attribute_55           -0.0          1.003\n",
              "attribute_56           -0.0          1.003\n",
              "attribute_57           -0.0          1.003\n",
              "attribute_58           -0.0          1.003\n",
              "attribute_59           -0.0          1.003\n",
              "attribute_60           -0.0          1.003"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wnXd1rOwXOv"
      },
      "source": [
        "### Categorical preprocessing\n",
        "\n",
        "We took very small steps when walking through the numeric preprocessing pipeline. Now that we have seen the general principles, we will go through the categorical preprocessing pipeline more quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical data are typically preprocessed by imputing (in our example using the 'most_frequent' value), and by 'OneHotEncoding', defining dummy variables out of categorical features."
      ],
      "metadata": {
        "id": "Oy5KNMP2Gqjn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrBYJ-UwwWhm"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "        ('cat_imputer', SimpleImputer(strategy = 'most_frequent')),\n",
        "        ('cat_encoder', OneHotEncoder(sparse=False))])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cQx6XYu2jOH",
        "outputId": "83c74fd9-141c-4c78-f551-48bc59bc641f"
      },
      "source": [
        "cat_pipeline.fit(X_train[cat_features])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
              "                ('cat_encoder', OneHotEncoder(sparse=False))])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz1LHJtm2sTP",
        "outputId": "bd38fa30-b16e-44c9-8b40-1e5599a0dcc2"
      },
      "source": [
        "cat_pipeline['cat_imputer'].statistics_"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['third', 'loc_E'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi0BiNs85DXG"
      },
      "source": [
        "X_cat_prep = cat_pipeline.transform(X_train[cat_features])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 7\n",
        "- Compare the dimensions of the unpreprocessed and the preprocessed categorical data and explain the difference.\n",
        "- Apply .get_feature_names_out(cat_features) to the categorical encoder component of the pipeline to extract dummy names.\n",
        "- Create a pandas dataframe containing the prepared categorical features along with the appropriate column names."
      ],
      "metadata": {
        "id": "YfUyi-asH9NE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAp_j8ZC5PYj",
        "outputId": "64e6ca05-6fa4-4e11-b6ba-3ce3316c7676"
      },
      "source": [
        "# Answer Q7\n",
        "print('dimension of the original categorical data: ' + str(X_train[cat_features].shape))\n",
        "print('dimension of the preprocessed categorical data: ' + str(X_cat_prep.shape))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension of the original categorical data: (145, 2)\n",
            "dimension of the preprocessed categorical data: (145, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi5yeexx5iV8"
      },
      "source": [
        "Answer Q7 - continued:\n",
        "\n",
        "Our prepared data now contains 8 columns, while we started with 2 categorical features. This is due to the OneHotEncoder transforming the two categorical features (containing 3, and 5 levels) into 1 feature for each level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y41D8BDh7tKi",
        "outputId": "fa3d30dd-eb8b-419b-b89d-c8fca2ace80e"
      },
      "source": [
        "# Answer Q7 - continued\n",
        "# Feature names of these 8 variables are easily accessed through:\n",
        "cat_pipeline['cat_encoder'].get_feature_names_out(cat_features)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['batch_first', 'batch_second', 'batch_third', 'location_loc_A',\n",
              "       'location_loc_B', 'location_loc_C', 'location_loc_D',\n",
              "       'location_loc_E'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "KC-7ObFy8Zds",
        "outputId": "c51d206e-1075-4fea-dfdf-a3efbe1d3110"
      },
      "source": [
        "# Answer Q7 - continued\n",
        "cat_names = cat_pipeline['cat_encoder'].get_feature_names_out(cat_features)\n",
        "pd.DataFrame(X_cat_prep, columns = cat_names).head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6460b142-6ee5-4d77-a2b7-2f86fb794cc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_first</th>\n",
              "      <th>batch_second</th>\n",
              "      <th>batch_third</th>\n",
              "      <th>location_loc_A</th>\n",
              "      <th>location_loc_B</th>\n",
              "      <th>location_loc_C</th>\n",
              "      <th>location_loc_D</th>\n",
              "      <th>location_loc_E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6460b142-6ee5-4d77-a2b7-2f86fb794cc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6460b142-6ee5-4d77-a2b7-2f86fb794cc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6460b142-6ee5-4d77-a2b7-2f86fb794cc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   batch_first  batch_second  batch_third  location_loc_A  location_loc_B  \\\n",
              "0          0.0           0.0          1.0             0.0             0.0   \n",
              "1          0.0           0.0          1.0             0.0             0.0   \n",
              "2          0.0           0.0          1.0             0.0             0.0   \n",
              "3          0.0           1.0          0.0             0.0             0.0   \n",
              "4          0.0           1.0          0.0             0.0             0.0   \n",
              "\n",
              "   location_loc_C  location_loc_D  location_loc_E  \n",
              "0             0.0             0.0             1.0  \n",
              "1             0.0             0.0             1.0  \n",
              "2             0.0             0.0             1.0  \n",
              "3             0.0             1.0             0.0  \n",
              "4             0.0             1.0             0.0  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWNUKG_v9CtJ"
      },
      "source": [
        "### Full Pipeline\n",
        "\n",
        "Now that we have constructed the numeric and categorical pipeline, we can define the full pipeline, simply as the combination of both pipelines, wrapped in a ColumnTransformer, which allows for different subsets of features to be passed on to each pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TSGy1OQ9bWm"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_features),\n",
        "        (\"cat\", cat_pipeline, cat_features)])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5-yVLgtAm8t"
      },
      "source": [
        "By applying the fit_transform functionality, this could be applied straight away to the raw data and provide the fully prepared data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "n-CbifgwBrBJ",
        "outputId": "fc2bd381-df37-4f04-e30e-582da979eb6e"
      },
      "source": [
        "X_train_prep = full_pipeline.fit_transform(X_train)\n",
        "pd.DataFrame(X_train_prep, columns=[num_features.tolist() + cat_names.tolist()]).head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4861b658-a09b-4d65-ad1c-fe58f1ff9c98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>...</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>batch_first</th>\n",
              "      <th>batch_second</th>\n",
              "      <th>batch_third</th>\n",
              "      <th>location_loc_A</th>\n",
              "      <th>location_loc_B</th>\n",
              "      <th>location_loc_C</th>\n",
              "      <th>location_loc_D</th>\n",
              "      <th>location_loc_E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.926945</td>\n",
              "      <td>0.502972</td>\n",
              "      <td>1.794994</td>\n",
              "      <td>1.247895</td>\n",
              "      <td>-0.910411</td>\n",
              "      <td>0.007312</td>\n",
              "      <td>-0.227513</td>\n",
              "      <td>-1.084874</td>\n",
              "      <td>0.391854</td>\n",
              "      <td>-0.383149</td>\n",
              "      <td>...</td>\n",
              "      <td>4.360670</td>\n",
              "      <td>3.606635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.137929</td>\n",
              "      <td>-0.638156</td>\n",
              "      <td>-0.315623</td>\n",
              "      <td>-0.652323</td>\n",
              "      <td>0.133136</td>\n",
              "      <td>0.494733</td>\n",
              "      <td>0.089465</td>\n",
              "      <td>0.260823</td>\n",
              "      <td>0.158578</td>\n",
              "      <td>-0.022404</td>\n",
              "      <td>...</td>\n",
              "      <td>0.335082</td>\n",
              "      <td>0.824793</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.187845</td>\n",
              "      <td>0.132105</td>\n",
              "      <td>0.179579</td>\n",
              "      <td>0.207629</td>\n",
              "      <td>-0.250042</td>\n",
              "      <td>0.482235</td>\n",
              "      <td>0.046886</td>\n",
              "      <td>0.431239</td>\n",
              "      <td>0.820094</td>\n",
              "      <td>0.590127</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.215374</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.778517</td>\n",
              "      <td>-0.592511</td>\n",
              "      <td>-0.056002</td>\n",
              "      <td>1.029934</td>\n",
              "      <td>2.109716</td>\n",
              "      <td>-0.196821</td>\n",
              "      <td>-0.796811</td>\n",
              "      <td>-0.317415</td>\n",
              "      <td>-0.914150</td>\n",
              "      <td>-0.844020</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.224460</td>\n",
              "      <td>0.800603</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.587172</td>\n",
              "      <td>-0.381402</td>\n",
              "      <td>-0.505530</td>\n",
              "      <td>-0.376901</td>\n",
              "      <td>-0.187537</td>\n",
              "      <td>-1.138334</td>\n",
              "      <td>-0.331595</td>\n",
              "      <td>0.030468</td>\n",
              "      <td>-0.236458</td>\n",
              "      <td>-0.602542</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.965261</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 68 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4861b658-a09b-4d65-ad1c-fe58f1ff9c98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4861b658-a09b-4d65-ad1c-fe58f1ff9c98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4861b658-a09b-4d65-ad1c-fe58f1ff9c98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  attribute_1 attribute_2 attribute_3 attribute_4 attribute_5 attribute_6  \\\n",
              "0    0.926945    0.502972    1.794994    1.247895   -0.910411    0.007312   \n",
              "1   -0.137929   -0.638156   -0.315623   -0.652323    0.133136    0.494733   \n",
              "2   -0.187845    0.132105    0.179579    0.207629   -0.250042    0.482235   \n",
              "3   -0.778517   -0.592511   -0.056002    1.029934    2.109716   -0.196821   \n",
              "4   -0.587172   -0.381402   -0.505530   -0.376901   -0.187537   -1.138334   \n",
              "\n",
              "  attribute_7 attribute_8 attribute_9 attribute_10  ... attribute_59  \\\n",
              "0   -0.227513   -1.084874    0.391854    -0.383149  ...     4.360670   \n",
              "1    0.089465    0.260823    0.158578    -0.022404  ...     0.335082   \n",
              "2    0.046886    0.431239    0.820094     0.590127  ...    -0.550859   \n",
              "3   -0.796811   -0.317415   -0.914150    -0.844020  ...    -0.224460   \n",
              "4   -0.331595    0.030468   -0.236458    -0.602542  ...    -0.550859   \n",
              "\n",
              "  attribute_60 batch_first batch_second batch_third location_loc_A  \\\n",
              "0     3.606635         0.0          0.0         1.0            0.0   \n",
              "1     0.824793         0.0          0.0         1.0            0.0   \n",
              "2    -0.215374         0.0          0.0         1.0            0.0   \n",
              "3     0.800603         0.0          1.0         0.0            0.0   \n",
              "4    -0.965261         0.0          1.0         0.0            0.0   \n",
              "\n",
              "  location_loc_B location_loc_C location_loc_D location_loc_E  \n",
              "0            0.0            0.0            0.0            1.0  \n",
              "1            0.0            0.0            0.0            1.0  \n",
              "2            0.0            0.0            0.0            1.0  \n",
              "3            0.0            0.0            1.0            0.0  \n",
              "4            0.0            0.0            1.0            0.0  \n",
              "\n",
              "[5 rows x 68 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV_hXT28GpJH"
      },
      "source": [
        "And that's it! Now the training data is fully prepared and ready for the phase of model building. Below you find the full code needed to set up the pipeline, without all the detours taken above, resulting in a compact block of code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_3Gol5IGxI"
      },
      "source": [
        "#from sklearn.pipeline import Pipeline\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.impute import SimpleImputer\n",
        "\n",
        "#num_pipeline = Pipeline([\n",
        "#        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "#        ('std_scaler', StandardScaler()),\n",
        "#    ])\n",
        "#\n",
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "#\n",
        "#cat_pipeline = Pipeline([\n",
        "#        ('cat_imputer', SimpleImputer(strategy = 'most_frequent')),\n",
        "#        ('cat_encoder', OneHotEncoder(sparse=False))])\n",
        "#\n",
        "#from sklearn.compose import ColumnTransformer\n",
        "#\n",
        "#full_pipeline = ColumnTransformer([\n",
        "#        (\"num\", num_pipeline, num_features),\n",
        "#        (\"cat\", cat_pipeline, cat_features)])\n",
        "#\n",
        "#num_features = X_train.select_dtypes(include=['float']).columns\n",
        "#cat_features = X_train.select_dtypes(exclude=['float']).columns\n",
        "#X_train_prep = full_pipeline.fit_transform(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy4ACaEvxM9y"
      },
      "source": [
        "## Training and evaluating a machine learning model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtJ7pFv27tB0"
      },
      "source": [
        "### Question 8\n",
        "- Train a LASSO model using the prepared train data and save the outcomes in a 'results' object (as in the previous notebook).\n",
        "- Assess the results on the training data by showing performance for different hyperparameter values, and by displaying the confusion matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Q8\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logL1_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
        "lasso_alphas = np.linspace(0.1, 20, 200)\n",
        "grid = dict()\n",
        "grid['C'] = lasso_alphas\n",
        "gscv = GridSearchCV(logL1_clf, grid, scoring='accuracy', cv = cv, n_jobs=-1)\n",
        "results = gscv.fit(X_train_prep, y_train)"
      ],
      "metadata": {
        "id": "7-4hXHtANweJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Q8 - continued\n",
        "results.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stnDXyQKON7H",
        "outputId": "0e61822f-eff1-431a-93ae-e11fdd515162"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.4, penalty='l1', solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Q8 - continued\n",
        "# plot accuracy for different values of C\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lasso_alphas, results.cv_results_ ['mean_test_score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "ULPBMbzhOQSQ",
        "outputId": "4ad0d1b3-3254-4d23-8aaf-ebee65b909ca"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f105bac8150>]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Q8 - continued\n",
        "# get coefficients\n",
        "results.best_estimator_.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL6xstNPOVAz",
        "outputId": "e3a8a44a-d062-48c1-cb05-943dee55633f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.14141528,  0.        ,  0.        ,  0.        , -0.08457593,\n",
              "         0.        ,  0.16399513,  0.        ,  0.        ,  0.        ,\n",
              "        -0.45534805, -0.19598733,  0.        ,  0.13732605,  0.16919906,\n",
              "         0.13201218,  0.        ,  0.        ,  0.        , -0.38319604,\n",
              "         0.        ,  0.        , -0.03348074, -0.0077538 ,  0.        ,\n",
              "         0.        ,  0.        , -0.14394787,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.14933143,  0.        ,  0.31678248,\n",
              "         0.        ,  0.        ,  0.        ,  0.        ,  0.03807652,\n",
              "         0.        ,  0.        ,  0.        , -0.30761782, -0.31161718,\n",
              "         0.        ,  0.        , -0.11525457, -0.02291123,  0.        ,\n",
              "        -0.0859967 ,  0.        , -0.01578473,  0.        ,  0.        ,\n",
              "         0.        ,  0.        , -0.24669139, -0.67671816,  0.        ,\n",
              "         1.39503898,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.73332645, -1.30718648, -2.02138658]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Q8 - continued\n",
        "cm = confusion_matrix(y_train, results.best_estimator_.predict(X_train_prep), labels=results.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=results.classes_)\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "okCjw65xOd8i",
        "outputId": "0bb9271a-746a-4988-ffda-664423a1dc5e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f105bac8090>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy obtained from predicting training data outcomes, using:"
      ],
      "metadata": {
        "id": "hBumiMMXRQj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(results.predict(X_train_prep), y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yqY85FJR36O",
        "outputId": "296c496e-d228-4c37-b6d2-b9eeeb3af316"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9655172413793104"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "is different from the accuracy reported in the 'best_score_':"
      ],
      "metadata": {
        "id": "ad9LdIthSBVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSwiKNXWSMk-",
        "outputId": "e2cc3bfd-5707-4e06-8f0a-f94f1572dfb5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8873563218390805"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 9\n",
        "- explain the difference, considering that results.best_score_ is the maximum value in results.cv_results_['mean_test_score']\n",
        "- apply the best LASSO model to the test data using accuracy_score(results.predict(X_test), y_test)\n",
        "- prepare the test features using the full_pipeline and check the means and standard deviations of the prepared test features\n",
        "- provide the confusion matrix for the test data"
      ],
      "metadata": {
        "id": "5h2R8mQURMZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Q9:\n",
        "\n",
        "The difference is due to best_score_ taking the average of the performance on the folds not used for model building, whereas using the model to predict outcomes for X_train_prep will apply the model to all the instances used for fitting that model, which will generally greatly exaggerate model performance as we are now assessing the model on data on which it was also trained."
      ],
      "metadata": {
        "id": "7weE9SdCUIWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Q9 - continued\n",
        "accuracy_score(results.predict(X_test), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "op4vQhTLUkI7",
        "outputId": "66f1ed44-cef8-4cab-bcbf-dce8989d4f62"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-150040f9f783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Answer Q9 - continued\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'third'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "kJ88A73RBsCR",
        "outputId": "f9f09d8e-4282-40ae-bc91-5a870d3ff7cd"
      },
      "source": [
        "# Answer Q9 - continued\n",
        "X_test_prep = full_pipeline.transform(X_test)\n",
        "X_test_prep = pd.DataFrame(X_test_prep, columns=[num_features.tolist() + cat_names.tolist()])\n",
        "X_test_prep.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0e22ffa0-e7dc-4f0e-b75d-fd3fbe43b899\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>...</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>batch_first</th>\n",
              "      <th>batch_second</th>\n",
              "      <th>batch_third</th>\n",
              "      <th>location_loc_A</th>\n",
              "      <th>location_loc_B</th>\n",
              "      <th>location_loc_C</th>\n",
              "      <th>location_loc_D</th>\n",
              "      <th>location_loc_E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.312634</td>\n",
              "      <td>-0.504073</td>\n",
              "      <td>-0.457452</td>\n",
              "      <td>0.039206</td>\n",
              "      <td>-0.519081</td>\n",
              "      <td>-0.498855</td>\n",
              "      <td>0.155699</td>\n",
              "      <td>-0.684103</td>\n",
              "      <td>-0.674914</td>\n",
              "      <td>-0.431003</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.844312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.383349</td>\n",
              "      <td>-0.738005</td>\n",
              "      <td>-1.099291</td>\n",
              "      <td>-0.250087</td>\n",
              "      <td>-0.067964</td>\n",
              "      <td>1.134211</td>\n",
              "      <td>0.396981</td>\n",
              "      <td>-0.183433</td>\n",
              "      <td>-0.140253</td>\n",
              "      <td>-0.594443</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.504230</td>\n",
              "      <td>-1.062021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.845071</td>\n",
              "      <td>-0.318640</td>\n",
              "      <td>-0.678610</td>\n",
              "      <td>-0.406622</td>\n",
              "      <td>-0.602420</td>\n",
              "      <td>-1.702826</td>\n",
              "      <td>-1.501731</td>\n",
              "      <td>-0.835714</td>\n",
              "      <td>0.055562</td>\n",
              "      <td>0.379570</td>\n",
              "      <td>...</td>\n",
              "      <td>0.117482</td>\n",
              "      <td>-0.021854</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.071374</td>\n",
              "      <td>0.189162</td>\n",
              "      <td>-0.469472</td>\n",
              "      <td>-0.796970</td>\n",
              "      <td>-0.660395</td>\n",
              "      <td>-0.059344</td>\n",
              "      <td>-0.102929</td>\n",
              "      <td>0.553468</td>\n",
              "      <td>0.233499</td>\n",
              "      <td>0.652706</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.504230</td>\n",
              "      <td>-0.263754</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.312634</td>\n",
              "      <td>0.037962</td>\n",
              "      <td>0.718051</td>\n",
              "      <td>0.461256</td>\n",
              "      <td>-0.412190</td>\n",
              "      <td>-0.180157</td>\n",
              "      <td>-1.768245</td>\n",
              "      <td>-0.808683</td>\n",
              "      <td>-0.456963</td>\n",
              "      <td>-0.207562</td>\n",
              "      <td>...</td>\n",
              "      <td>0.863537</td>\n",
              "      <td>1.260212</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 68 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e22ffa0-e7dc-4f0e-b75d-fd3fbe43b899')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e22ffa0-e7dc-4f0e-b75d-fd3fbe43b899 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e22ffa0-e7dc-4f0e-b75d-fd3fbe43b899');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  attribute_1 attribute_2 attribute_3 attribute_4 attribute_5 attribute_6  \\\n",
              "0   -0.312634   -0.504073   -0.457452    0.039206   -0.519081   -0.498855   \n",
              "1   -0.383349   -0.738005   -1.099291   -0.250087   -0.067964    1.134211   \n",
              "2   -0.845071   -0.318640   -0.678610   -0.406622   -0.602420   -1.702826   \n",
              "3   -0.071374    0.189162   -0.469472   -0.796970   -0.660395   -0.059344   \n",
              "4   -0.312634    0.037962    0.718051    0.461256   -0.412190   -0.180157   \n",
              "\n",
              "  attribute_7 attribute_8 attribute_9 attribute_10  ... attribute_59  \\\n",
              "0    0.155699   -0.684103   -0.674914    -0.431003  ...    -0.550859   \n",
              "1    0.396981   -0.183433   -0.140253    -0.594443  ...    -0.504230   \n",
              "2   -1.501731   -0.835714    0.055562     0.379570  ...     0.117482   \n",
              "3   -0.102929    0.553468    0.233499     0.652706  ...    -0.504230   \n",
              "4   -1.768245   -0.808683   -0.456963    -0.207562  ...     0.863537   \n",
              "\n",
              "  attribute_60 batch_first batch_second batch_third location_loc_A  \\\n",
              "0    -0.844312         0.0          0.0         1.0            0.0   \n",
              "1    -1.062021         0.0          0.0         1.0            0.0   \n",
              "2    -0.021854         1.0          0.0         0.0            0.0   \n",
              "3    -0.263754         1.0          0.0         0.0            0.0   \n",
              "4     1.260212         0.0          1.0         0.0            0.0   \n",
              "\n",
              "  location_loc_B location_loc_C location_loc_D location_loc_E  \n",
              "0            0.0            0.0            0.0            1.0  \n",
              "1            0.0            0.0            0.0            1.0  \n",
              "2            0.0            0.0            0.0            1.0  \n",
              "3            0.0            0.0            0.0            1.0  \n",
              "4            0.0            0.0            1.0            0.0  \n",
              "\n",
              "[5 rows x 68 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Q9 - continued\n",
        "mean = X_test_prep[num_features].mean(axis=0).round(3)\n",
        "std = X_test_prep[num_features].std(axis=0).round(3)\n",
        "pd.DataFrame({'Prepped_Means':mean, 'Prepped_Scale':std}, index=X_test_prep[num_features].columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6S73k3LeVNru",
        "outputId": "01094b7a-fb35-4d40-d4a1-7822bea88a18"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9aeedc8-0873-4e90-a66d-06732be8ae1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prepped_Means</th>\n",
              "      <th>Prepped_Scale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>attribute_1</th>\n",
              "      <td>-0.180</td>\n",
              "      <td>0.772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_2</th>\n",
              "      <td>-0.061</td>\n",
              "      <td>0.693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_3</th>\n",
              "      <td>-0.225</td>\n",
              "      <td>0.585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_4</th>\n",
              "      <td>-0.183</td>\n",
              "      <td>0.641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_5</th>\n",
              "      <td>-0.214</td>\n",
              "      <td>0.679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_6</th>\n",
              "      <td>-0.133</td>\n",
              "      <td>1.117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_7</th>\n",
              "      <td>-0.248</td>\n",
              "      <td>0.791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_8</th>\n",
              "      <td>-0.164</td>\n",
              "      <td>0.769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_9</th>\n",
              "      <td>-0.157</td>\n",
              "      <td>0.854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_10</th>\n",
              "      <td>-0.140</td>\n",
              "      <td>0.906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_11</th>\n",
              "      <td>-0.228</td>\n",
              "      <td>1.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_12</th>\n",
              "      <td>-0.042</td>\n",
              "      <td>1.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_13</th>\n",
              "      <td>-0.201</td>\n",
              "      <td>1.092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_14</th>\n",
              "      <td>-0.252</td>\n",
              "      <td>0.906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_15</th>\n",
              "      <td>-0.297</td>\n",
              "      <td>0.967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_16</th>\n",
              "      <td>-0.112</td>\n",
              "      <td>0.947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_17</th>\n",
              "      <td>-0.120</td>\n",
              "      <td>0.894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_18</th>\n",
              "      <td>-0.229</td>\n",
              "      <td>0.832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_19</th>\n",
              "      <td>-0.054</td>\n",
              "      <td>0.872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_20</th>\n",
              "      <td>0.081</td>\n",
              "      <td>0.955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_21</th>\n",
              "      <td>0.023</td>\n",
              "      <td>0.987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_22</th>\n",
              "      <td>0.050</td>\n",
              "      <td>0.994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_23</th>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_24</th>\n",
              "      <td>-0.014</td>\n",
              "      <td>1.027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_25</th>\n",
              "      <td>-0.020</td>\n",
              "      <td>0.985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_26</th>\n",
              "      <td>-0.150</td>\n",
              "      <td>0.998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_27</th>\n",
              "      <td>-0.182</td>\n",
              "      <td>1.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_28</th>\n",
              "      <td>-0.041</td>\n",
              "      <td>1.141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_29</th>\n",
              "      <td>0.108</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_30</th>\n",
              "      <td>0.106</td>\n",
              "      <td>1.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_31</th>\n",
              "      <td>-0.022</td>\n",
              "      <td>1.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_32</th>\n",
              "      <td>0.046</td>\n",
              "      <td>0.942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_33</th>\n",
              "      <td>0.049</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_34</th>\n",
              "      <td>0.141</td>\n",
              "      <td>1.069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_35</th>\n",
              "      <td>0.098</td>\n",
              "      <td>1.177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_36</th>\n",
              "      <td>0.015</td>\n",
              "      <td>1.022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_37</th>\n",
              "      <td>0.044</td>\n",
              "      <td>0.932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_38</th>\n",
              "      <td>-0.064</td>\n",
              "      <td>0.941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_39</th>\n",
              "      <td>-0.038</td>\n",
              "      <td>1.038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_40</th>\n",
              "      <td>-0.030</td>\n",
              "      <td>1.029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_41</th>\n",
              "      <td>-0.161</td>\n",
              "      <td>1.038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_42</th>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_43</th>\n",
              "      <td>0.044</td>\n",
              "      <td>1.051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_44</th>\n",
              "      <td>-0.028</td>\n",
              "      <td>1.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_45</th>\n",
              "      <td>-0.074</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_46</th>\n",
              "      <td>-0.033</td>\n",
              "      <td>1.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_47</th>\n",
              "      <td>0.031</td>\n",
              "      <td>0.914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_48</th>\n",
              "      <td>-0.107</td>\n",
              "      <td>0.840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_49</th>\n",
              "      <td>-0.243</td>\n",
              "      <td>0.874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_50</th>\n",
              "      <td>-0.119</td>\n",
              "      <td>0.937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_51</th>\n",
              "      <td>0.071</td>\n",
              "      <td>0.993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_52</th>\n",
              "      <td>0.035</td>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_53</th>\n",
              "      <td>0.230</td>\n",
              "      <td>1.209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_54</th>\n",
              "      <td>-0.136</td>\n",
              "      <td>0.767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_55</th>\n",
              "      <td>-0.148</td>\n",
              "      <td>0.715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_56</th>\n",
              "      <td>0.067</td>\n",
              "      <td>0.815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_57</th>\n",
              "      <td>0.017</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_58</th>\n",
              "      <td>-0.033</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_59</th>\n",
              "      <td>-0.123</td>\n",
              "      <td>0.763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_60</th>\n",
              "      <td>-0.078</td>\n",
              "      <td>0.789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9aeedc8-0873-4e90-a66d-06732be8ae1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9aeedc8-0873-4e90-a66d-06732be8ae1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9aeedc8-0873-4e90-a66d-06732be8ae1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              Prepped_Means  Prepped_Scale\n",
              "attribute_1          -0.180          0.772\n",
              "attribute_2          -0.061          0.693\n",
              "attribute_3          -0.225          0.585\n",
              "attribute_4          -0.183          0.641\n",
              "attribute_5          -0.214          0.679\n",
              "attribute_6          -0.133          1.117\n",
              "attribute_7          -0.248          0.791\n",
              "attribute_8          -0.164          0.769\n",
              "attribute_9          -0.157          0.854\n",
              "attribute_10         -0.140          0.906\n",
              "attribute_11         -0.228          1.020\n",
              "attribute_12         -0.042          1.021\n",
              "attribute_13         -0.201          1.092\n",
              "attribute_14         -0.252          0.906\n",
              "attribute_15         -0.297          0.967\n",
              "attribute_16         -0.112          0.947\n",
              "attribute_17         -0.120          0.894\n",
              "attribute_18         -0.229          0.832\n",
              "attribute_19         -0.054          0.872\n",
              "attribute_20          0.081          0.955\n",
              "attribute_21          0.023          0.987\n",
              "attribute_22          0.050          0.994\n",
              "attribute_23         -0.001          0.979\n",
              "attribute_24         -0.014          1.027\n",
              "attribute_25         -0.020          0.985\n",
              "attribute_26         -0.150          0.998\n",
              "attribute_27         -0.182          1.100\n",
              "attribute_28         -0.041          1.141\n",
              "attribute_29          0.108          1.000\n",
              "attribute_30          0.106          1.024\n",
              "attribute_31         -0.022          1.087\n",
              "attribute_32          0.046          0.942\n",
              "attribute_33          0.049          0.980\n",
              "attribute_34          0.141          1.069\n",
              "attribute_35          0.098          1.177\n",
              "attribute_36          0.015          1.022\n",
              "attribute_37          0.044          0.932\n",
              "attribute_38         -0.064          0.941\n",
              "attribute_39         -0.038          1.038\n",
              "attribute_40         -0.030          1.029\n",
              "attribute_41         -0.161          1.038\n",
              "attribute_42         -0.006          0.994\n",
              "attribute_43          0.044          1.051\n",
              "attribute_44         -0.028          1.006\n",
              "attribute_45         -0.074          0.896\n",
              "attribute_46         -0.033          1.026\n",
              "attribute_47          0.031          0.914\n",
              "attribute_48         -0.107          0.840\n",
              "attribute_49         -0.243          0.874\n",
              "attribute_50         -0.119          0.937\n",
              "attribute_51          0.071          0.993\n",
              "attribute_52          0.035          0.990\n",
              "attribute_53          0.230          1.209\n",
              "attribute_54         -0.136          0.767\n",
              "attribute_55         -0.148          0.715\n",
              "attribute_56          0.067          0.815\n",
              "attribute_57          0.017          0.979\n",
              "attribute_58         -0.033          0.808\n",
              "attribute_59         -0.123          0.763\n",
              "attribute_60         -0.078          0.789"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWJH1WBlB852"
      },
      "source": [
        "Answer Q9 - continued \n",
        "\n",
        "Be careful not to use 'fit_transform' with the pipeline, but only 'transform', as we have to use the fitted information (scaling etc) from the training data. One way to remember this is to see the test data as something that does not come in batches, but in single instances: you want your model to work on new, single observations. A single observation cannot be scaled to mean 0 and standard deviation 1, which is one way to remember why we apply the preprocessing parameters derived in the train set to prepare the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Q9 - continued\n",
        "cm = confusion_matrix(y_test, results.predict(X_test_prep), labels=results.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=results.classes_)\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "mvEmlD04M7JN",
        "outputId": "39e0e131-7973-4ea2-edd0-fee1e395c9a4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f1058259ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgmh9mfzCyTR",
        "outputId": "b4120184-51fa-4aa3-ec1d-2eb34df49fc1"
      },
      "source": [
        "# Answer Q9 - continued\n",
        "accuracy_score(results.predict(X_test_prep), y_test)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.873015873015873"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG219z6ohceY"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "This notebook took a 'small step by small step' approach to developing a model. Sklearn has extensive functionalities, and the risk in using such a powerful module is that you lose sight of what is happening and start leaning on the preprogrammed features too easily. \n",
        "\n",
        "Especially when you start out working with sklearn and its wide array of applications, it really pays off to take this step by step approach to keep track of what is happening as much as possible. "
      ]
    }
  ]
}